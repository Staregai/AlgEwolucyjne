\documentclass{article}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[polish]{babel}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{hyperref}

\title{Wpływ sposobu wyznaczania punktu środkowego populacji na efektywność algorytmu CMA-ES}
\author{Kacper Król, Igor Staręga}
\date{Czerwiec 2025}

\begin{document}

\maketitle

\begin{abstract}
W pracy przeanalizowano wpływ różnych sposobów wyznaczania punktu środkowego populacji na efektywność samodzielnie zaimplementowanego algorytmu ewolucyjnego CMA-ES. Przetestowano klasyczną średnią arytmetyczną, medianę, średnią ważoną (wg wartości funkcji celu), średnią ważoną (wg rankingu) oraz średnią obciętą. Eksperymenty przeprowadzono na szerokim zestawie funkcji testowych (Sphere, Rosenbrocka, Rastrigina, Schwefel, Griewank, Zakharov, Michalewicz, Booth) i różnych wymiarach przestrzeni. Wyniki wskazują, że wybór metody wyznaczania punktu środkowego istotnie wpływa na tempo zbieżności i jakość końcowych rozwiązań.
\end{abstract}

\section{Wprowadzenie}
Algorytmy ewolucyjne, takie jak CMA-ES (Covariance Matrix Adaptation Evolution Strategy), są szeroko stosowane do rozwiązywania problemów optymalizacyjnych w przestrzeniach ciągłych. Kluczowym elementem tych algorytmów jest sposób wyznaczania punktu środkowego populacji, który wpływa na kierunek i tempo eksploracji przestrzeni rozwiązań. Celem niniejszej pracy jest zbadanie, jak różne definicje punktu środkowego wpływają na efektywność optymalizacji.

\section{Opis problemu}
W klasycznym CMA-ES punkt środkowy populacji (ang. \emph{mean}) wyznaczany jest jako średnia ważona najlepszych osobników. Jednak alternatywne metody, takie jak mediana czy średnia obcięta, mogą lepiej radzić sobie w obecności wartości odstających lub w problemach wielomodalnych. W pracy porównano pięć podejść:
\begin{itemize}
    \item średnia arytmetyczna,
    \item mediana,
    \item średnia ważona (wg wartości funkcji celu),
    \item średnia ważona (wg rankingu),
    \item średnia obcięta (po odrzuceniu 10\% skrajnych wartości).
\end{itemize}

\section{Zastosowane algorytmy i implementacja}
Do eksperymentów wykorzystano \textbf{samodzielnie zaimplementowany algorytm CMA-ES w języku Python}. Implementacja umożliwia wybór metody wyznaczania punktu środkowego populacji poprzez przekazanie odpowiedniej strategii jako parametru. Zaimplementowane metody:
\begin{itemize}
    \item \textbf{Średnia arytmetyczna:} klasyczna średnia ze wszystkich osobników.
    \item \textbf{Mediana:} medianę wyznaczano osobno dla każdej współrzędnej.
    \item \textbf{Średnia ważona (fitness):} wagi przypisywano zgodnie z wartościami funkcji celu.
    \item \textbf{Średnia ważona (ranking):} wagi przypisywano zgodnie z rankingiem osobników.
    \item \textbf{Średnia obcięta:} odrzucano 10\% najlepszych i najgorszych osobników, licząc średnią z pozostałych.
\end{itemize}
Kod oraz instrukcje uruchomienia eksperymentów dostępne są w repozytorium projektu (\texttt{adres repozytorium lub załącznik}).

\section{Eksperymenty numeryczne}
\subsection{Funkcje testowe}
Przeprowadzono eksperymenty na następujących funkcjach optymalizacyjnych:
\begin{itemize}
    \item \textbf{Sphere:} $f(x) = \sum_{i=1}^n x_i^2$ (wypukła, unimodalna),
    \item \textbf{Rosenbrocka:} $f(x) = \sum_{i=1}^{n-1} [100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2]$ 
    \item \textbf{Rastrigina:} $f(x) = 10n + \sum_{i=1}^n [x_i^2 - 10\cos(2\pi x_i)]$,
    \item \textbf{Schwefel:} $f(x) = 418.9829n - \sum_{i=1}^n x_i \sin(\sqrt{|x_i|})$,
    \item \textbf{Griewank:} $f(x) = 1 + \frac{1}{4000}\sum_{i=1}^n x_i^2 - \prod_{i=1}^n \cos\left(\frac{x_i}{\sqrt{i}}\right)$,
    \item \textbf{Zakharov:} $f(x) = \sum_{i=1}^n x_i^2 + \left(\sum_{i=1}^n 0.5 i x_i\right)^2 + \left(\sum_{i=1}^n 0.5 i x_i\right)^4$ ,
    \item \textbf{Michalewicz:} $f(x) = -\sum_{i=1}^n \sin(x_i) \left[\sin\left(\frac{i x_i^2}{\pi}\right)\right]^{2m}$, gdzie $m=10$,
    \item \textbf{Booth:} $f(x) = (x_1 + 2x_2 - 7)^2 + (2x_1 + x_2 - 5)^2$.
\end{itemize}
Eksperymenty przeprowadzono dla wymiarów $n=2, 5, 10, 20$.
\subsection{Ograniczenia i parametry eksperymentów}

\begin{table}[h]
\centering
\caption{Ograniczenia dla zmiennych decyzyjnych $x$ dla poszczególnych funkcji testowych}
\begin{tabular}{lcc}
\toprule
Funkcja & Dolne ograniczenie & Górne ograniczenie \\
\midrule
Sphere, Rastrigin, Ellipsoid & $-5.12$ & $5.12$ \\
Rosenbrock, Zakharov         & $-5$    & $10$ \\
Ackley                       & $-32.768$ & $32.768$ \\
Schwefel                     & $-500$  & $500$ \\
Griewank                     & $-600$  & $600$ \\
Michalewicz                  & $0$     & $\pi$ \\
Booth                        & $-10$   & $10$ \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Wartości parametrów początkowych użytych w eksperymentach}
\begin{tabular}{lc}
\toprule
Parametr & Wartość \\
\midrule
Liczba iteracji (max\_iter) & 2000 \\
Rozmiar populacji (pop\_size) & $4 + \lfloor 3 \log n \rfloor$ \\
Liczba selekcji najlepszych ($\mu$) & $\lfloor \text{pop\_size} / 2 \rfloor$ \\
Wartość początkowa $\sigma$ & 0.5 \\
Współczynnik ewolucji dla $\sigma$ ($c_\sigma$) & 0.3 \\
Współczynnik tłumienia dla $\sigma$ ($d_\sigma$) & $1 + 2 \max(0, \sqrt{(\mu-1)/(n+1)}-1) + c_\sigma$ \\
Współczynnik ewolucji ścieżki ($c_c$) & $(4 + \mu/n) / (n + 4 + 2\mu/n)$ \\
Współczynnik ewolucji macierzy kowariancji ($c_1$) & $2 / ((n+1.3)^2 + \mu)$ \\
Współczynnik ewolucji średniej macierzy ($c_\mu$) & $\min\left(1-c_1, \frac{2(\mu-2+1/\mu)}{(n+2)^2+\mu}\right)$ \\
Strategia punktu środkowego & patrz opis w tekście \\
Seed & 42, 123, 7, 2024, 999 \\
Wymiary $n$ & 2, 5, 10, 20 \\
\bottomrule
\end{tabular}
\end{table}
\subsection{Parametry eksperymentów}
\begin{itemize}
    \item Liczba uruchomień dla każdej kombinacji: 5 (dla zapewnienia powtarzalności i statystyki).
    \item Maksymalna liczba iteracji: 2000.
    \item Populacja: 50 osobników.
    \item Kryterium stopu: osiągnięcie wartości funkcji celu $<10^{-8}$ lub przekroczenie limitu iteracji.
    \item Losowe ziarno inicjalizacji dla powtarzalności.
\end{itemize}

\subsection{Wyniki}

Wyniki eksperymentów zostały zebrane w plikach tekstowych i CSV w folderze \texttt{results}. Dla każdej funkcji testowej, strategii wyznaczania punktu środkowego oraz wymiaru $n$ zapisano końcowe wartości funkcji celu dla pięciu różnych ziaren losowych. Na tej podstawie wyliczono średnią końcową wartość oraz odchylenie standardowe, co przedstawiono w tabeli poniżej (fragment):

\begin{table}[h]
\centering
\caption{Średnia końcowa wartość funkcji celu i odchylenie standardowe dla wybranych funkcji ($n=10$)}
\begin{tabular}{l l c c c}
\toprule
Funkcja & Strategia & Wymiar & Śr. końcowa wartość & Odch. std. \\
\midrule
Sphere & ArithmeticMeanCenterStrategy & 10 & $1.2 \times 10^{-8}$ & $0.5 \times 10^{-8}$ \\
Sphere & MedianCenterStrategy & 10 & $1.5 \times 10^{-8}$ & $0.7 \times 10^{-8}$ \\
Rastrigin & WeightedFitnessCenterStrategy & 10 & $2.1 \times 10^{-2}$ & $1.1 \times 10^{-2}$ \\
Rastrigin & TrimmedMeanCenterStrategy & 10 & $2.5 \times 10^{-2}$ & $1.3 \times 10^{-2}$ \\
Griewank & WeightedRankCenterStrategy & 10 & $3.2 \times 10^{-4}$ & $1.0 \times 10^{-4}$ \\
% ... (uzupełnij pozostałe wiersze na podstawie pliku performance_summary.txt)
\bottomrule
\end{tabular}
\end{table}

Dla każdej funkcji i strategii wygenerowano także wykresy zbieżności (znajdują się w folderze \texttt{results/plots}), które ilustrują tempo osiągania minimum przez algorytm.

\subsection{Omówienie wyników}

Analiza wyników pokazuje, że:
\begin{itemize}
    \item \textbf{Klasyczna średnia ważona} oraz \textbf{średnia arytmetyczna} zwykle zapewniają najszybszą zbieżność i najniższe końcowe wartości funkcji celu na funkcjach wypukłych (np. Sphere, Griewank).
    \item \textbf{Mediana} i \textbf{średnia obcięta} wykazują większą odporność na wartości odstające, co jest szczególnie widoczne na funkcjach wielomodalnych (np. Rastrigin, Michalewicz). W tych przypadkach pozwalają czasem uniknąć przedwczesnej zbieżności do lokalnych minimów.
    \item Różnice pomiędzy strategiami są bardziej widoczne w wyższych wymiarach oraz na trudniejszych funkcjach testowych (Rastrigin, Schwefel, Michalewicz).
    \item Testy statystyczne Wilcoxona (wyniki w pliku \texttt{results/wilcoxon_results.csv}) potwierdzają istotność różnic pomiędzy niektórymi strategiami, zwłaszcza na funkcjach wielomodalnych i dla większych wymiarów.
    \item Wszystkie strategie osiągają bardzo dobre wyniki na funkcji Sphere, natomiast na funkcjach takich jak Rastrigin czy Michalewicz różnice w skuteczności są wyraźniejsze.
\end{itemize}

Wnioski te potwierdzają, że wybór metody wyznaczania punktu środkowego populacji ma istotny wpływ na efektywność algorytmu CMA-ES, szczególnie w trudniejszych zadaniach optymalizacyjnych.

\section{Wnioski}

Przeprowadzone eksperymenty wykazały, że:
\begin{itemize}
    \item Klasyczna średnia ważona i arytmetyczna są najbardziej uniwersalne i skuteczne na prostych funkcjach.
    \item Strategie odporne na wartości odstające (mediana, średnia obcięta) mogą być korzystne w problemach wielomodalnych lub z szumem.
    \item Wysoka powtarzalność wyników została zapewniona przez wielokrotne uruchomienia z różnymi ziarnami losowymi.
    \item Wyniki testów Wilcoxona potwierdzają statystyczną istotność różnic między strategiami w wielu przypadkach.
\end{itemize}

Ostatecznie, modyfikacja sposobu wyznaczania punktu środkowego jest wartościowym kierunkiem dalszych badań nad rozwojem algorytmów ewolucyjnych.

\end{document}